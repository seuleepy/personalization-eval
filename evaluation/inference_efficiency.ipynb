{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d34b09a-acf4-4f73-8c92-bfe8d113f96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/seulgi/anaconda3/envs/dreambooth/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "from diffusers import StableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8dfb0f1-b961-4fe0-996e-b8d5077bad5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|██████████████████████████████████████| 7/7 [00:26<00:00,  3.77s/it]\n"
     ]
    }
   ],
   "source": [
    "pipeline = StableDiffusionPipeline.from_pretrained(\n",
    "    \"/input/model/path\",\n",
    "    torch_dtype=torch.float16).to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695b14a6-6872-4921-bbc6-aa1b45ff6d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_sd_latency(pipe, prompt, num_images=1, repeat=10):\n",
    "    # Warm-up\n",
    "    _ = pipe(prompt, num_images_per_prompt=num_images)\n",
    "    torch.cuda.synchronize() # Wait until GPU operations are complete\n",
    "\n",
    "    # Clear memory tracking\n",
    "    torch.cuda.reset_peak_memory_stats() # Reset peak memory usage from previous runs\n",
    "    \n",
    "    start = time.time()\n",
    "    for _ in range(repeat):\n",
    "        _ = pipe(prompt, num_images_per_prompt=num_images)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    \n",
    "    avg_latency = (end - start) / repeat\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / 1024**2\n",
    "    \n",
    "    return avg_latency, peak_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bf0b4c0-98f5-4f22-a607-10c8d915bbcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.80it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.57it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.58it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.52it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.09it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.42it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg latency: 2028.93 ms\n",
      "Peak GPU memory: 3269.06 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "latency, memory = measure_sd_latency(pipeline, \"a sks backpack on a wooden table\" , num_images=1, repeat=30)\n",
    "print(f\"Avg latency: {latency*1000:.2f} ms\")\n",
    "print(f\"Peak GPU memory: {memory:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f42fd79-4434-4ea0-a3fe-e2752823dd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_sd_latency_event(pipe, prompt, num_images=1, repeat=10):\n",
    "    pipe(prompt, num_images_per_prompt=num_images) # wram-up\n",
    "    torch.cuda.synchronize()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "    total_time = 0.0\n",
    "\n",
    "    for _ in range(repeat):\n",
    "        start_event = torch.cuda.Event(enable_timing=True)\n",
    "        end_event = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "        start_event.record()\n",
    "        _ = pipe(prompt, num_images_per_prompt=num_images)\n",
    "        end_event.record()\n",
    "\n",
    "        torch.cuda.synchronize()\n",
    "        elapsed = start_event.elapsed_time(end_event)\n",
    "        total_time += elapsed\n",
    "\n",
    "    avg_latency = total_time / repeat\n",
    "    peak_memory = torch.cuda.max_memory_allocated() / 1024**2\n",
    "\n",
    "    return avg_latency, peak_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2feaefba-37a6-437d-b277-002df5089e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.70it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.64it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.60it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.75it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.78it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.76it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.79it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.66it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.81it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg latency: 2023.91 ms\n",
      "Peak GPU memory: 3269.06 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "latency, memory = measure_sd_latency_event(pipeline, \"a sks backpack on a wooden table\" , num_images=1, repeat=30)\n",
    "print(f\"Avg latency: {latency:.2f} ms\") # No need to multiply by 1000 since the result is already in milliseconds\n",
    "print(f\"Peak GPU memory: {memory:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c36a857f-6b9c-4a7e-9dfd-51f39588c235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch size: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:01<00:00, 25.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2018.63ms | FPS: 0.50 | Per image: 2018.63ms\n",
      "\n",
      "Batch size: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 16.18it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:03<00:00, 16.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 3192.50ms | FPS: 0.63 | Per image: 1596.25ms\n",
      "\n",
      "Batch size: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.37it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:05<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 6226.56ms | FPS: 0.64 | Per image: 1556.64ms\n",
      "\n",
      "Batch size: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:11<00:00,  4.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████| 50/50 [00:11<00:00,  4.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 11633.50ms | FPS: 0.69 | Per image: 1454.19ms\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [1, 2, 4, 8]\n",
    "prompt = \"a sks backpack on a wooden table\"\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "\n",
    "    print(f\"\\nBatch size: {batch_size}\")\n",
    "\n",
    "    # Warm-up run\n",
    "    _ = pipeline(prompt, num_images_per_prompt=batch_size)\n",
    "\n",
    "    # Start measurement\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    _ = pipeline(prompt, num_images_per_prompt=batch_size)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "\n",
    "    elapsed = (end - start)\n",
    "    elapsed_ms = elapsed * 1000\n",
    "    fps = batch_size / elapsed\n",
    "    per_image_time = elapsed_ms / batch_size\n",
    "\n",
    "    print(f\"Time: {elapsed_ms:.2f}ms | FPS: {fps:.2f} | Per image: {per_image_time:.2f}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a309f6-fa4f-4498-b400-74b5558c447d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dreambooth",
   "language": "python",
   "name": "dreambooth"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
